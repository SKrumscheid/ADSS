{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42a396b4-e86d-4a83-ab1a-bd9db8fe9fd2",
   "metadata": {},
   "source": [
    "# Example\n",
    "\n",
    "This minimal example introduces the basic workflow for using the Adaptive Stratified Sampling package and showcases its features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e282b8c-6329-4bbe-a45b-e9cd09f2d5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Import the modules, note that the package already needs to be installed\n",
    "import adaptive_stratification as adss\n",
    "from adaptive_stratification.stratification import AdaptiveStratification as estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac719999-480b-4348-b22a-0905a0aaf595",
   "metadata": {},
   "source": [
    "## Problem set-up\n",
    "\n",
    "We begin by defining a test function. As an example, here we use the function\n",
    "\n",
    "$f(\\xi_1,\\xi_2, \\dots, \\xi_d) = I\\left(\\sum_{i=1}^d\\xi_i^2\\le r^2\\right)$\n",
    "\n",
    "with $r = \\sqrt{2/\\pi}$. For $d=2$, this value of $r$ yields a true expected value of $0.5$.\n",
    "\n",
    "Note that this particular test function can be used flexibly for different dimensions. The actual dimension $d$ for the input needs to be set during the instantiation of the 'solver' below.\n",
    "\n",
    "Recall that the function $f$ needs to be defined on the $d$-dimensional unit cube. Depending on your problem, it may thus be necessary to transform the problem formulation. This is not needed here, of course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e577514a-dd22-4422-93b4-a522f6b690a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_fun(xi: np.ndarray):\n",
    "    # xi contains sampling points within the d-dimensional unit cube. \n",
    "    return np.sum(xi ** 2, axis=1) <= 0.7978845608028654 ** 2  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d04500",
   "metadata": {},
   "source": [
    "Next, we define the sampling procedure's settings, including the problem dimension $d$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7955fd03",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.9  # alpha: proportion of samples allocated optimally\n",
    "N_max = int(1e4)  # numbers of max samples used\n",
    "SR_const = 30  # increase per adaptation iteration\n",
    "dimension = 2 # stochastic dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336ee2e0-b590-4424-8d15-8ba941dd5e57",
   "metadata": {},
   "source": [
    "### Hyperrectangular tessellation\n",
    "Now, we can run the Adaptive Stratified Sampling routine. First, we use an adaptive stratification based on hyperrectangles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4d865d-0794-42c4-8242-0a10fdeb271b",
   "metadata": {},
   "outputs": [],
   "source": [
    "est_hyper = estimator(test_fun, dimension, N_max, SR_const, alpha, type_strat='hyperrect', rand_gen=None, dynamic=False)\n",
    "QoI, ignore, N_strat, QoI_var = est_hyper.solve()\n",
    "print(f'After splitting the domain into {N_strat} strata, we found that the quantity of interest is {QoI} with an estimated variance of {QoI_var}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b43782-5a95-4a70-8757-7ac1c81dca81",
   "metadata": {},
   "source": [
    "### Simplex tessellation\n",
    "Next, we repeat the same experiment using adaptive stratification based on simplices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cccda230-e93c-4816-87f1-d3a51a7b5e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "est_simp = estimator(test_fun, dimension, N_max, SR_const, alpha, type_strat='simplex', rand_gen=None, dynamic=False)\n",
    "QoI, ignore, N_strat, QoI_var = est_simp.solve()\n",
    "print(f'After splitting the domain into {N_strat} strata, we found that the quantity of interest is {QoI} with an estimated variance of {QoI_var}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87875625-3e01-4449-85ca-348e5bb965e2",
   "metadata": {},
   "source": [
    "## Visualization\n",
    "\n",
    "For the cases where the output is either one or two-dimensional, you can use the visualization feature provided in the sub-package to either show a picture depicting the stratification in each step or at the end.\n",
    "\n",
    "### Show the final stratification\n",
    "For example, to show the final stratification, we can use the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa581378-1d26-408f-96d2-48cbaf0f15fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from adaptive_stratification.visualization.plot_stratification import AdaptiveStratificationVisualization as AdaptiveStratification\n",
    "\n",
    "estimator_result = AdaptiveStratification(test_fun, dimension, N_max, SR_const, alpha, dynamic=False, type_strat='hyperrect', rand_gen=None)\n",
    "QoI, ignore, N_strat, QoI_var = estimator_result.solve_vis_result()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88fbbf3-948d-4602-ad14-bd0e9e563c01",
   "metadata": {},
   "source": [
    "### Show current stratification at each step\n",
    "Similarly, to show the current stratification at each step as the adaptation progresses, we use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2bb971f-aa01-401a-91c1-3a8060441ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator_steps = AdaptiveStratification(test_fun, dimension, N_max, SR_const, alpha, dynamic=False, type_strat='hyperrect', rand_gen=None)\n",
    "QoI, ignore, N_strat, QoI_var = estimator_steps.solve_vis_steps()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35873e3-bc71-4218-a636-836395a29e62",
   "metadata": {},
   "source": [
    "## Logging\n",
    "Finally, the Adaptive Stratified Sampling package comes with a logging functionality, which can be used as shown below. There we use a one-dimensional test function, where we already obtain the optimal stratification (i.e., zero variance) after one split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc50e3a-9f56-4dfb-aa01-30b35e270ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "# Import the root package logger\n",
    "strat_logger = logging.getLogger(adss.__name__)\n",
    "\n",
    "# set the desired logging level\n",
    "strat_logger.setLevel(logging.DEBUG)\n",
    "\n",
    "# and add the corresponding hanlder andd formatter.\n",
    "c_handler = logging.StreamHandler()\n",
    "c_handler.setLevel(logging.DEBUG)\n",
    "c_formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "c_handler.setFormatter(c_formatter)\n",
    "strat_logger.addHandler(c_handler)\n",
    "\n",
    "# Using the one dimensional case, where we already have the optimal solution after one split.\n",
    "dimension = 1\n",
    "\n",
    "def test_fun(xi: np.ndarray):\n",
    "    return np.sum(xi ** 2, axis=1) <= 0.5 ** 2\n",
    "\n",
    "est_hyper = estimator(test_fun, dimension, 1000, SR_const, alpha, type_strat='hyperrect', rand_gen=None, dynamic=False)\n",
    "QoI, ignore, N_strat, QoI_var = est_hyper.solve()\n",
    "print(f'After splitting the domain into {N_strat} strata, we found that the quantity of interest is {QoI} with a variance of {QoI_var}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
